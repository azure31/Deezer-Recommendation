{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prahita\\Anaconda2\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import scipy.io as spi\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read train, user-features and item-features matrices and sparsify them\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"G:\\\\PGDBA\\\\Kaggle\\\\DSG2017\\\\data\\\\train.csv\")\n",
    "test = pd.read_csv(\"G:\\\\PGDBA\\\\Kaggle\\\\DSG2017\\\\data\\\\test.csv\")\n",
    "#user_item= pd.read_csv(\"C:\\\\Users\\\\pkhande5\\\\Desktop\\\\Kaggle\\\\deezer_sample.csv\")\n",
    "#user_item=  sps.csr_matrix(user_item, dtype=np.int16) \n",
    "# Save the matrix. They are already in csr format\n",
    "#spi.mmwrite(\"user_item.mtx\", user_item) \n",
    "        \n",
    "user_feat = pd.read_csv(\"G:\\\\PGDBA\\\\Kaggle\\\\DSG2017\\\\data\\\\user_features.csv\")\n",
    "song_feat = pd.read_csv(\"G:\\\\PGDBA\\\\Kaggle\\\\DSG2017\\\\data\\\\item_features.csv\")\n",
    "song_feat['song_hash_id']= range(song_feat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data= pd.concat([train, test])\n",
    "all_data=all_data.ix[:, ['user_id', 'media_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a hash of indexes\n",
    "media_index= {key: value for (value, key) in enumerate(song_feat['media_id'].values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#uf['index']= [user_index[k] for k in uf['user_id'].values]\n",
    "#mf['index']=[media_index[k] for k in mf['media_id'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert train to user-item matrix # Build the user x item matrices using scipy lil_matrix \n",
    "n_row= len(all_data['user_id'].unique())\n",
    "n_col= len(all_data['media_id'].unique())\n",
    "\n",
    "user_item_mat = sps.lil_matrix(((n_row), (n_col)), dtype=np.int8)\n",
    "for i in range(len(train)): \n",
    "    sys.stdout.write( \"\\rProcessing row \" + str(i) + \"/ \" + str(train.shape[0])) \n",
    "    sys.stdout.flush() \n",
    "    ui, mi = train[\"user_id\"].values[i],  media_index[train[\"media_id\"].values[i]] \n",
    "    user_item_mat[ui, mi] = train[\"is_listened\"].values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf_mat= sps.csr_matrix(mf, dtype=np.int16)\n",
    "uf_mat= sps.csr_matrix(uf, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(user_item_mat,\n",
    "          user_features=uf_mat,\n",
    "          item_features=mf_mat,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(uf['index'],\n",
    "                            mf['index'],\n",
    "                            user_features=uf_mat,\n",
    "                            item_features=mf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "\n",
    "    #number of users and movies in training data\n",
    "    n_users, n_items = data['train'].shape\n",
    "\n",
    "    #generate recommendations for each user we input\n",
    "    for user_id in user_ids:\n",
    "\n",
    "        #movies they already like\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "\n",
    "        #movies our model predicts they will like\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        #rank them in order of most liked to least\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        #print out the results\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "\n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "\n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
